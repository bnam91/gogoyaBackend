from kiwipiepy import Kiwi
from collections import Counter
import pandas as pd

# 1. ë¶ˆìš©ì–´ ì •ì˜
STOPWORDS = {
    # ëŒ€ëª…ì‚¬
    'ë‚˜', 'ë„ˆ', 'ì €', 'ê·¸', 'ì´', 'ê²ƒ', 'ê±°', 'ë‚˜', 'ë‚´', 'ëˆ„êµ¬', 'ì–´ë””', 'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì €ê²ƒ',
    # ì¡°ì‚¬
    'ì˜', 'ê°€', 'ì´', 'ì€', 'ëŠ”', 'ì„', 'ë¥¼', 'ì—', 'ì™€', 'ê³¼', 'ë¡œ', 'ìœ¼ë¡œ', 'ì—ê²Œ', 'ì—ì„œ', 'ê¹Œì§€', 'ë¶€í„°', 'ë§Œ', 'ë„', 'ë§Œí¼',
    # ì¼ë°˜ ëª…ì‚¬
    'ë•Œ', 'ìˆ˜', 'ì¤‘', 'ì•', 'ë’¤', 'ìœ„', 'ì•„ë˜', 'ë‚ ', 'ë‹¬', 'ì‹œê°„', 'ì‚¬ëŒ', 'ê²½ìš°', 'ì •ë„', 'ë²ˆ', 'ì‹œ', 'ë¶„', 'ì´ˆ',
    # ì˜ì¡´ ëª…ì‚¬
    'ê²ƒ', 'ë°', 'ë“¯', 'ì¤„', 'ë§Œí¼', 'ë²ˆ', 'ê°€ì§€', 'ë•Œë¬¸',
    # ì¼ë°˜ì ì¸ ë™ì‚¬/í˜•ìš©ì‚¬
    'í•˜ë‹¤', 'ë˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ê°™ë‹¤', 'ì´ë‹¤', 'ì•„ë‹ˆë‹¤', 'ë§ë‹¤',
    # ë¶€ì‚¬
    'ë˜', 'ê·¸ëƒ¥', 'ì¢€', 'ì˜', 'ë”', 'ë§ì´', 'ë„ˆë¬´', 'ë§¤ìš°', 'ì•„ì£¼', 'ì¡°ê¸ˆ', 'ì•½ê°„', 'ë‹¤ì‹œ', 'ì—´ì‹¬íˆ',
    # ìˆ˜ì‚¬
    'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬', 'ì‹­', 'ë°±', 'ì²œ', 'ë§Œ', 'ì–µ',
    # ê¸°íƒ€
    'ë“±', 'ë“¤', 'ë°', 'ì—ì„œ', 'ê¹Œì§€', 'ì–´ìš”', 'ìŠµë‹ˆë‹¤', 'á†«ê°€', 'ê·¸ë¦¬ê³ ', 'ì–´ì„œ', 'ë¼ê³ ', 'ì•„ë‹ˆ', 'á†¯ë¡œ', 'ì§€ë§Œ', 'ìœ¼ì‹œ', 'ê¸°ì—',
    # íŠ¹ìˆ˜ë¬¸ì
    '..', '...', '~', '!', '?', 'ğŸŒ¸'
}

# 2. ë³µí•© ëª…ì‚¬ íŒ¨í„´ ì •ì˜
COMPOUND_PATTERNS = [
    ('ìœ ê¸°ë†', 'ìƒë¦¬ëŒ€'),
    ('ì‹ ë°œ', 'ê¹”ì°½'),
    ('ê¸°ë¶€', 'ì'),
    ('ì¹œêµ¬', 'ë“¤'),
    ('ì¹­êµ¬', 'ë“¤'),
    ('ìƒë¦¬', 'ëŒ€'),
    ('ìœ ê¸°', 'ë†')
]

# 3. Excel íŒŒì¼ì—ì„œ ë°ì´í„° ì½ê¸°
df = pd.read_excel('jiemma_posts.xlsx')
text = ' '.join(df['content'].dropna().astype(str))

# 4. Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì¤€ë¹„
kiwi = Kiwi()

# 5. í’ˆì‚¬ë³„ ë‹¨ì–´ ì¶”ì¶œ (ë¶ˆìš©ì–´ ì œê±°)
nouns = []      # ëª…ì‚¬
adjectives = [] # í˜•ìš©ì‚¬
verbs = []      # ë™ì‚¬

# 6. ë³µí•© ëª…ì‚¬ ì²˜ë¦¬ í•¨ìˆ˜
def process_compound_nouns(tokens):
    result = []
    i = 0
    while i < len(tokens):
        # ë³µí•© ëª…ì‚¬ íŒ¨í„´ í™•ì¸
        found_compound = False
        for pattern in COMPOUND_PATTERNS:
            if i + len(pattern) <= len(tokens):
                words = [tokens[j].form for j in range(i, i + len(pattern))]
                if tuple(words) == pattern:
                    result.append(''.join(words))
                    i += len(pattern)
                    found_compound = True
                    break
        if not found_compound:
            result.append(tokens[i].form)
            i += 1
    return result

# 7. í† í°í™” ë° ë‹¨ì–´ ì¶”ì¶œ
tokens = list(kiwi.tokenize(text))
processed_nouns = process_compound_nouns(tokens)

for token in tokens:
    word = token.form
    if word in STOPWORDS:  # ë¶ˆìš©ì–´ ì²´í¬
        continue
        
    # ëª…ì‚¬ íƒœê·¸ í™•ì¸ (NNP: ê³ ìœ ëª…ì‚¬, NNG: ì¼ë°˜ëª…ì‚¬, XR: ì–´ê·¼)
    if token.tag in ['NNP', 'NNG', 'XR'] and len(word) > 1:
        nouns.append(word)
    elif token.tag == 'VA':  # í˜•ìš©ì‚¬
        if word + "ë‹¤" not in STOPWORDS:  # ë¶ˆìš©ì–´ ì²´í¬
            adjectives.append(word + "ë‹¤")
    elif token.tag == 'VV':  # ë™ì‚¬
        if word + "ë‹¤" not in STOPWORDS:  # ë¶ˆìš©ì–´ ì²´í¬
            verbs.append(word + "ë‹¤")

# 8. ë¹ˆë„ìˆ˜ ê³„ì‚°
noun_counter = Counter(nouns)
adj_counter = Counter(adjectives)
verb_counter = Counter(verbs)

# 9. ê²°ê³¼ ì¶œë ¥
def print_counter(title, counter, percentile=10):
    print(f"\n=== {title} (ìƒìœ„ {percentile}%) ===")
    # ë¹ˆë„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    sorted_items = sorted(counter.items(), key=lambda x: x[1], reverse=True)
    
    # ìƒìœ„ percentile% ê³„ì‚°
    total_items = len(sorted_items)
    top_n = max(1, int(total_items * percentile / 100))
    
    result = []
    for word, count in sorted_items[:top_n]:
        result.append(f"{word}({count}íšŒ)")
    print(", ".join(result))

print_counter("ì˜ë¯¸ìˆëŠ” ëª…ì‚¬", noun_counter)
print_counter("ì˜ë¯¸ìˆëŠ” í˜•ìš©ì‚¬", adj_counter)
print_counter("ì˜ë¯¸ìˆëŠ” ë™ì‚¬", verb_counter)
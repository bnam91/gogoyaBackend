from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time
import os
import shutil
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from datetime import datetime, timezone, timedelta
import json
import random
from googleapiclient.discovery import build
import sys
from pymongo import MongoClient
from pymongo.server_api import ServerApi
from urllib.parse import urlparse, urlunsplit

# auth.py íŒŒì¼ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from auth import get_credentials
from module.reels_analyzer import ReelsAnalyzer

def clean_url(url):
    """URLì—ì„œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜"""
    parsed = urlparse(url)
    clean = urlunsplit((parsed.scheme, parsed.netloc, parsed.path, '', ''))
    return clean

def load_processed_posts(collection):
    """MongoDBì—ì„œ ê²Œì‹œë¬¼ URLë“¤ì„ ë¡œë“œ (ìµœì í™”ëœ ë²„ì „)"""
    processed_posts = set()
    
    try:
        # MongoDBì—ì„œ URLë§Œ ì„ íƒì ìœ¼ë¡œ ë¡œë“œ (í”„ë¡œì ì…˜ ì‚¬ìš©)
        mongo_posts = collection.find(
            {}, 
            {"post_url": 1, "_id": 0},
            batch_size=1000  # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        )
        
        # URLë§Œ ì¶”ì¶œí•˜ì—¬ setì— ì¶”ê°€
        processed_posts = {post["post_url"] for post in mongo_posts if "post_url" in post}
        print(f"ğŸš©MongoDBì—ì„œ {len(processed_posts)}ê°œì˜ ê²Œì‹œë¬¼ URLì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"MongoDB ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ë¹ˆ setì„ ë°˜í™˜í•˜ì—¬ í¬ë¡¤ë§ì„ ê³„ì†í•  ìˆ˜ ìˆë„ë¡ í•¨
        return set()
    
    return processed_posts

# MongoDB ì—°ê²° ì„¤ì •
def connect_mongodb():
    uri = "mongodb+srv://coq3820:JmbIOcaEOrvkpQo1@cluster0.qj1ty.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0"
    client = MongoClient(uri, server_api=ServerApi('1'),
                        connectTimeoutMS=60000,  # ì—°ê²° íƒ€ì„ì•„ì›ƒì„ 60ì´ˆë¡œ ì¦ê°€
                        socketTimeoutMS=60000)   # ì†Œì¼“ íƒ€ì„ì•„ì›ƒë„ 60ì´ˆë¡œ ì¦ê°€

    try:
        # ì—°ê²° í™•ì¸
        client.admin.command('ping')
        print("MongoDB ì—°ê²° ì„±ê³µ!")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì™€ ì»¬ë ‰ì…˜ ì„ íƒ
        db = client['insta09_database']
        collection_feed = db['01_main_newfeed_crawl_data']
        collection_influencer = db['02_main_influencer_data']
        
        # post_urlì— Unique Index ìƒì„±
        collection_feed.create_index("post_url", unique=True)
        print("post_urlì— Unique Indexê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        return collection_feed, collection_influencer
    except Exception as e:
        print(f"MongoDB ì—°ê²° ë˜ëŠ” ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        return None, None

def update_mongodb_data(values, collection):
    """MongoDBì— ë°ì´í„° ì €ì¥"""
    try:
        post_url = clean_url(values[3])  # URL íŒŒë¼ë¯¸í„° ì œê±°
        
        # ì¤‘ë³µ ì²´í¬
        existing_post = collection.find_one({"post_url": post_url})
        if existing_post:
            print(f"\nì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²Œì‹œë¬¼ì…ë‹ˆë‹¤: {post_url}")
            return True

        # MongoDB ë°ì´í„° êµ¬ì„±
        post_data = {
            "cr_at": values[0],
            "author": values[1],
            "content": values[2],
            "post_url": post_url,
            "crawl_date": datetime.now(timezone(timedelta(hours=9))),  # KST ê¸°ì¤€
            "09_feed": "",
            "09_brand": "",
            "09_item": "",
            "09_item_category": "",
            "09_item_category_2": "",
            "open_date": "",
            "end_date": "",
            "processed": False
        }
        
        # MongoDBì— ë°ì´í„° ì €ì¥
        collection.insert_one(post_data)
        print(f"\nìƒˆë¡œìš´ ê²Œì‹œë¬¼ì´ MongoDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {post_url}")
        return True

    except Exception as e:
        print(f"MongoDB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def clear_chrome_data(user_data_dir, keep_login=True):
    default_dir = os.path.join(user_data_dir, 'Default')
    if not os.path.exists(default_dir):
        print("Default ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    dirs_to_clear = ['Cache', 'Code Cache', 'GPUCache']
    files_to_clear = ['History', 'Visited Links', 'Web Data']
    
    for dir_name in dirs_to_clear:
        dir_path = os.path.join(default_dir, dir_name)
        if os.path.exists(dir_path):
            shutil.rmtree(dir_path)
            print(f"{dir_name} ë””ë ‰í† ë¦¬ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")

    if not keep_login:
        files_to_clear.extend(['Cookies', 'Login Data'])

    for file_name in files_to_clear:
        file_path = os.path.join(default_dir, file_name)
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"{file_name} íŒŒì¼ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")

def is_within_period(date_str, weeks):
    try:
        post_date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        period_ago = datetime.now(timezone.utc) - timedelta(weeks=weeks)
        return post_date >= period_ago
    except Exception as e:
        print(f"ë‚ ì§œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def crawl_instagram_posts(driver, post_url, weeks, collection):
    try:
        # ê²Œì‹œë¬¼ ì¹´ìš´í„° ì´ˆê¸°í™” (ê¸°ê°„ ë‚´ ëª¨ë“  ê²Œì‹œë¬¼ ì¹´ìš´íŠ¸)
        total_posts_in_period = 0
        
        # ì²« ë²ˆì§¸ í”¼ë“œ ê²Œì‹œë¬¼ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div._aagv"))
        )
        
        # ì ì‹œ ëŒ€ê¸°
        time.sleep(3)
        
        # ì²« ë²ˆì§¸ ê²Œì‹œë¬¼ ì°¾ê¸°
        first_post = driver.find_element(By.CSS_SELECTOR, "div._aagv")
        
        # ë¶€ëª¨ ìš”ì†Œë¡œ ì´ë™í•˜ì—¬ ë§í¬ ì°¾ê¸°
        parent = first_post.find_element(By.XPATH, "./ancestor::a")
        post_link = parent.get_attribute("href")
        
        # JavaScriptë¡œ ì²« ë²ˆì§¸ ê²Œì‹œë¬¼ í´ë¦­
        print(f"\nì²« ë²ˆì§¸ ê²Œì‹œë¬¼({post_link})ì„ í´ë¦­í•©ë‹ˆë‹¤...")
        driver.execute_script("arguments[0].click();", parent)
        
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        time.sleep(3)
        
        try:
            # ê²Œì‹œë¬¼ ì •ë³´ ì¶”ì¶œ
            post_data = {}
            
            # ì‘ì„±ì ID ì¶”ì¶œ
            author_element = driver.find_element(By.CSS_SELECTOR, "a[role='link'][tabindex='0']")
            post_data['author'] = author_element.text
            
            # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
            content_element = driver.find_element(By.CSS_SELECTOR, "h1._ap3a._aaco._aacu._aacx._aad7._aade")
            post_data['content'] = content_element.text  # ì „ì²´ ë‚´ìš© ì €ì¥
            
            # ê²Œì‹œ ë‚ ì§œ ì¶”ì¶œ
            time_element = driver.find_element(By.CSS_SELECTOR, "time._a9ze._a9zf")
            post_date = time_element.get_attribute('datetime')
            
            # ì²˜ìŒ 3ê°œì˜ ê²Œì‹œë¬¼ì€ í•€ê³ ì • ê°€ëŠ¥ì„± ë•Œë¬¸ì— ë¬´ì¡°ê±´ í™•ì¸
            if total_posts_in_period < 3:
                total_posts_in_period += 1
                print(f"í•€ê³ ì • ê°€ëŠ¥ì„± ìˆëŠ” ê²Œì‹œë¬¼ {total_posts_in_period}/3 í™•ì¸ ì¤‘...")
            else:
                # 4ë²ˆì§¸ ê²Œì‹œë¬¼ë¶€í„° ê¸°ê°„ ì²´í¬
                if not is_within_period(post_date, weeks):
                    print(f"\n{weeks}ì£¼ ì´ì „ ê²Œì‹œë¬¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    return total_posts_in_period
                total_posts_in_period += 1  # ê¸°ê°„ ë‚´ ê²Œì‹œë¬¼ ì¹´ìš´íŠ¸ ì¦ê°€
            
            print(f"ê¸°ê°„ ë‚´ ì´ ê²Œì‹œë¬¼ ìˆ˜: {total_posts_in_period}")
            
            post_data['cr_at'] = post_date
            
            # ê²Œì‹œë¬¼ URL ì €ì¥ (íŒŒë¼ë¯¸í„° ì œê±°)
            post_url = clean_url(driver.current_url)
            post_data['post_url'] = post_url
            
            # í˜„ì¬ ì‹œê°„ ì¶”ê°€
            post_data['crawl_date'] = datetime.now(timezone.utc).isoformat()

            # ìƒˆë¡œìš´ í•„ë“œ ì¶”ê°€
            post_data['09_feed'] = ""
            post_data['09_brand'] = ""
            post_data['09_item'] = ""
            post_data['09_item_category'] = ""
            post_data['09_item_category_2'] = ""
            post_data['open_date'] = ""
            post_data['end_date'] = ""
            post_data['processed'] = False
            
            # MongoDBì— ë°ì´í„° ì €ì¥
            if collection is not None:
                try:
                    # post_urlë¡œ ì¤‘ë³µ ì²´í¬
                    existing_post = collection.find_one({"post_url": post_url})
                    if existing_post:
                        print(f"\nì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²Œì‹œë¬¼ì…ë‹ˆë‹¤: {post_url}")
                    else:
                        collection.insert_one(post_data)
                        print(f"\nì²« ë²ˆì§¸ í”¼ë“œ ì •ë³´ê°€ MongoDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    print(f"MongoDB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # ë‹¤ìŒ í”¼ë“œë¡œ ì´ë™ (1ì£¼ì¼ ì´ë‚´ì˜ ëª¨ë“  í”¼ë“œ)
            i = 1
            while True:  # ë¬´í•œ ë£¨í”„ë¡œ ë³€ê²½
                # ê²Œì‹œë¬¼ 100ê°œ ì œí•œ ì²´í¬
                if total_posts_in_period >= 100:
                    print("\n100ê°œì˜ ê²Œì‹œë¬¼ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ê³„ì •ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                    return total_posts_in_period
                    
                try:
                    # í˜„ì¬ URL ì €ì¥
                    current_url = driver.current_url
                    
                    # ë‹¤ìŒ ë²„íŠ¼ ì°¾ê¸°
                    next_button = None
                    selector = "//span[contains(@style, 'rotate(90deg)')]/.."  # 90ë„ íšŒì „ëœ í™”ì‚´í‘œ(ë‹¤ìŒ ë²„íŠ¼)ì˜ ë¶€ëª¨ ìš”ì†Œ
                    
                    print("\në‹¤ìŒ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
                    try:
                        next_button = driver.find_element(By.XPATH, selector)
                        if next_button.is_displayed():
                            print("ë‹¤ìŒ ë²„íŠ¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        print(f"ë‹¤ìŒ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                        break
                    
                    if next_button is None:
                        print(f"{i+1}ë²ˆì§¸ í”¼ë“œë¡œ ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        break
                    
                    print(f"\n{i+1}ë²ˆì§¸ í”¼ë“œë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                    driver.execute_script("arguments[0].click();", next_button)
                    
                    # ì‹¤ì œ ì‚¬ëŒì²˜ëŸ¼ ëœë¤í•œ ì‹œê°„ ëŒ€ê¸° (ì •ê·œ ë¶„í¬ ì‚¬ìš©)
                    wait_time = abs(random.gauss(3.5, 2))  # í‰ê·  6ì´ˆ, í‘œì¤€í¸ì°¨ 4ì´ˆ
                    # ìµœì†Œ 0.5ì´ˆ, ìµœëŒ€ 50ì´ˆë¡œ ì œí•œ
                    wait_time = max(0.5, min(wait_time, 30.0))
                    print(f"ë‹¤ìŒ í”¼ë“œ ë¡œë”© ëŒ€ê¸° ì¤‘... ({wait_time:.1f}ì´ˆ)")
                    time.sleep(wait_time)
                    
                    # URLì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if driver.current_url == current_url:
                        print(f"{i+1}ë²ˆì§¸ í”¼ë“œë¡œ ì´ë™í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. URLì´ ë³€ê²½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        print("í˜„ì¬ URL:", driver.current_url)
                        print("ì´ì „ URL:", current_url)
                        break
                    
                    # ë‹¤ìŒ í”¼ë“œ ì •ë³´ ì¶”ì¶œ
                    next_post_data = {}
                    
                    # ì‘ì„±ì ID ì¶”ì¶œ
                    author_element = driver.find_element(By.CSS_SELECTOR, "a[role='link'][tabindex='0']")
                    next_post_data['author'] = author_element.text
                    
                    # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
                    content_element = driver.find_element(By.CSS_SELECTOR, "h1._ap3a._aaco._aacu._aacx._aad7._aade")
                    next_post_data['content'] = content_element.text  # ì „ì²´ ë‚´ìš© ì €ì¥
                    
                    # ê²Œì‹œ ë‚ ì§œ ì¶”ì¶œ
                    time_element = driver.find_element(By.CSS_SELECTOR, "time._a9ze._a9zf")
                    post_date = time_element.get_attribute('datetime')
                    
                    # ì²˜ìŒ 3ê°œì˜ ê²Œì‹œë¬¼ì€ í•€ê³ ì • ê°€ëŠ¥ì„± ë•Œë¬¸ì— ë¬´ì¡°ê±´ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°
                    if total_posts_in_period < 3:
                        total_posts_in_period += 1
                        print(f"í•€ê³ ì • ê°€ëŠ¥ì„± ìˆëŠ” ê²Œì‹œë¬¼ {total_posts_in_period}/3 í™•ì¸ ì¤‘...")
                        # ê¸°ê°„ ë‚´ ê²Œì‹œë¬¼ì¸ ê²½ìš°ì—ë§Œ MongoDBì— ì €ì¥
                        if is_within_period(post_date, weeks):
                            next_post_data['cr_at'] = post_date
                            next_post_data['post_url'] = clean_url(driver.current_url)
                            next_post_data['crawl_date'] = datetime.now(timezone.utc).isoformat()
                            next_post_data['09_feed'] = ""
                            next_post_data['09_brand'] = ""
                            next_post_data['09_item'] = ""
                            next_post_data['09_item_category'] = ""
                            next_post_data['09_item_category_2'] = ""
                            next_post_data['open_date'] = ""
                            next_post_data['end_date'] = ""
                            next_post_data['processed'] = False
                            
                            try:
                                # MongoDBì— ì €ì¥ ì‹œë„
                                if collection is not None:
                                    existing_post = collection.find_one({"post_url": next_post_data['post_url']})
                                    if existing_post:
                                        print(f"\nì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²Œì‹œë¬¼ì…ë‹ˆë‹¤: {next_post_data['post_url']}")
                                    else:
                                        collection.insert_one(next_post_data)
                                        print(f"ê¸°ê°„ ë‚´ ê²Œì‹œë¬¼ì´ë¼ MongoDBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤: {next_post_data['post_url']}")
                            except Exception as e:
                                print(f"MongoDB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        else:
                            print(f"ê¸°ê°„ ì™¸ ê²Œì‹œë¬¼ì´ë¼ MongoDBì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    else:
                        # 4ë²ˆì§¸ ê²Œì‹œë¬¼ë¶€í„° ê¸°ê°„ ì²´í¬
                        if not is_within_period(post_date, weeks):
                            print(f"\n{weeks}ì£¼ ì´ì „ ê²Œì‹œë¬¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            return total_posts_in_period
                        total_posts_in_period += 1  # ê¸°ê°„ ë‚´ ê²Œì‹œë¬¼ ì¹´ìš´íŠ¸ ì¦ê°€
                        
                        # MongoDBì— ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
                        next_post_data['cr_at'] = post_date
                        next_post_data['post_url'] = clean_url(driver.current_url)
                        next_post_data['crawl_date'] = datetime.now(timezone.utc).isoformat()
                        next_post_data['09_feed'] = ""
                        next_post_data['09_brand'] = ""
                        next_post_data['09_item'] = ""
                        next_post_data['09_item_category'] = ""
                        next_post_data['09_item_category_2'] = ""
                        next_post_data['open_date'] = ""
                        next_post_data['end_date'] = ""
                        next_post_data['processed'] = False
                        
                        try:
                            # MongoDBì— ì €ì¥ ì‹œë„
                            if collection is not None:
                                existing_post = collection.find_one({"post_url": next_post_data['post_url']})
                                if existing_post:
                                    print(f"\nì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²Œì‹œë¬¼ì…ë‹ˆë‹¤: {next_post_data['post_url']}")
                                else:
                                    collection.insert_one(next_post_data)
                                    print(f"MongoDBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤: {next_post_data['post_url']}")
                        except Exception as e:
                            print(f"MongoDB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    
                    print(f"ê¸°ê°„ ë‚´ ì´ ê²Œì‹œë¬¼ ìˆ˜: {total_posts_in_period}")
                    
                    i += 1  # ì¹´ìš´í„° ì¦ê°€
                    
                except Exception as e:
                    print(f"{i+1}ë²ˆì§¸ í”¼ë“œë¡œ ì´ë™í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    break
            
        except Exception as e:
            print(f"ê²Œì‹œë¬¼ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print("í˜„ì¬ í˜ì´ì§€ ì†ŒìŠ¤:")
            print(driver.page_source[:500])  # í˜ì´ì§€ ì†ŒìŠ¤ì˜ ì¼ë¶€ë¥¼ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹…

    except Exception as e:
        print(f"ê²Œì‹œë¬¼ì„ í´ë¦­í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("í˜„ì¬ í˜ì´ì§€ ì†ŒìŠ¤:")
        print(driver.page_source[:500])  # í˜ì´ì§€ ì†ŒìŠ¤ì˜ ì¼ë¶€ë¥¼ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹…

    return total_posts_in_period

def update_crawl_date(service, spreadsheet_id, username, post_count, error_log=None):
    """Google Sheetsì˜ Date ì¹¼ëŸ¼ê³¼ Count ì¹¼ëŸ¼, Log ì¹¼ëŸ¼ì— í¬ë¡¤ë§ ë‚ ì§œì™€ ê²Œì‹œë¬¼ ìˆ˜, ì—ëŸ¬ ë¡œê·¸ ì—…ë°ì´íŠ¸"""
    try:
        # ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        result = service.spreadsheets().values().get(
            spreadsheetId=spreadsheet_id,
            range='A:G'  # Aì—´: Username, Bì—´: Category, Eì—´: Date, Fì—´: Count, Gì—´: Log
        ).execute()
        values = result.get('values', [])

        # usernameì´ ìˆëŠ” í–‰ ì°¾ê¸°
        row_number = None
        for i, row in enumerate(values):
            if row and row[0] == username:
                row_number = i + 1  # 1-based index
                break

        if row_number:
            # í˜„ì¬ ë‚ ì§œ í¬ë§·íŒ… (KST)
            kst = timezone(timedelta(hours=9))
            current_date = datetime.now(kst).strftime('%Y-%m-%d')

            # Date ì¹¼ëŸ¼(Eì—´), Count ì¹¼ëŸ¼(Fì—´), Log ì¹¼ëŸ¼(Gì—´) ì—…ë°ì´íŠ¸
            range_name = f'E{row_number}:G{row_number}'
            body = {
                'values': [[current_date, post_count, error_log if error_log else '']]
            }
            service.spreadsheets().values().update(
                spreadsheetId=spreadsheet_id,
                range=range_name,
                valueInputOption='RAW',
                body=body
            ).execute()
            print(f"\n{username}ì˜ í¬ë¡¤ë§ ë‚ ì§œê°€ {current_date}ë¡œ, ê²Œì‹œë¬¼ ìˆ˜ê°€ {post_count}ê°œë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if error_log:
                print(f"ì—ëŸ¬ ë¡œê·¸ê°€ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤: {error_log}")
        else:
            print(f"\n{username}ì„ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\ní¬ë¡¤ë§ ë‚ ì§œì™€ ê²Œì‹œë¬¼ ìˆ˜ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def check_already_crawled(service, spreadsheet_id, username):
    """í•´ë‹¹ usernameì˜ Date ì¹¼ëŸ¼ í™•ì¸"""
    try:
        # ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        result = service.spreadsheets().values().get(
            spreadsheetId=spreadsheet_id,
            range='A:E'  # Aì—´: Username, Bì—´: Category, Eì—´: Date
        ).execute()
        values = result.get('values', [])

        # usernameì´ ìˆëŠ” í–‰ ì°¾ê¸°
        for row in values:
            if row and row[0] == username:
                # Date ì¹¼ëŸ¼ì— ê°’ì´ ìˆëŠ”ì§€ í™•ì¸ (Eì—´)
                if len(row) > 4 and row[4].strip():  # Eì—´(ì¸ë±ìŠ¤ 4)ì— ê°’ì´ ìˆëŠ”ì§€ í™•ì¸
                    category = row[1] if len(row) > 1 else "ì¹´í…Œê³ ë¦¬ ì •ë³´ ì—†ìŒ"
                    print(f"\n{username} ê³„ì •ì€ ì´ë¯¸ {category}ì— í¬ë¡¤ë§ë˜ì—ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    return True, row[4]  # ì´ë¯¸ í¬ë¡¤ë§ë¨, ë‚ ì§œ ë°˜í™˜
                return False, None  # í¬ë¡¤ë§ ì•ˆë¨
    except Exception as e:
        print(f"\nDate ì¹¼ëŸ¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False, None

    return False, None

def update_reels_views(collection_influencer, username, average_views):
    """ì¸í”Œë£¨ì–¸ì„œ ì»¬ë ‰ì…˜ì˜ reels_views(15) í•„ë“œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    try:
        # ì •ìˆ˜ë¡œ ë³€í™˜
        views_int = int(average_views)
        
        # usernameìœ¼ë¡œ ë„íë¨¼íŠ¸ ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
        result = collection_influencer.update_one(
            {"username": username},
            {"$set": {"reels_views(15)": views_int}}
        )
        
        if result.matched_count > 0:
            print(f"\n{username}ì˜ reels_views(15) í•„ë“œê°€ {views_int:,}íšŒë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"\n{username}ì„ ì¸í”Œë£¨ì–¸ì„œ ì»¬ë ‰ì…˜ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"\nreels_views ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def take_break(username_count):
    """
    í¬ë¡¤ë§ ì¤‘ íœ´ì‹ ì‹œê°„ì„ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        username_count (int): í˜„ì¬ê¹Œì§€ ì²˜ë¦¬í•œ usernameì˜ ìˆ˜
    """
    def show_countdown(seconds, break_type):
        """ì¹´ìš´íŠ¸ë‹¤ìš´ì„ ë³´ì—¬ì£¼ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""
        start_time = time.time()
        while True:
            elapsed_time = int(time.time() - start_time)
            remaining = seconds - elapsed_time
            if remaining <= 0:
                break
            
            if break_type == "ì¤‘ê°„":
                mins, secs = divmod(remaining, 60)
                countdown = f"\r{break_type} íœ´ì‹ ì¤‘: {mins}ë¶„ {secs}ì´ˆ ë‚¨ìŒ...     "
            else:  # "ëŒ€ê·œëª¨"
                hours, remainder = divmod(remaining, 3600)
                mins, secs = divmod(remainder, 60)
                countdown = f"\r{break_type} íœ´ì‹ ì¤‘: {hours}ì‹œê°„ {mins}ë¶„ {secs}ì´ˆ ë‚¨ìŒ...     "
            
            print(countdown, end='', flush=True)
            time.sleep(1)
        print("\ríœ´ì‹ ì™„ë£Œ!            ")  # ì¹´ìš´íŠ¸ë‹¤ìš´ ì¢…ë£Œ í›„ ì¤„ ì •ë¦¬

    # ì¤‘ê°„ íœ´ì‹ (15-25ê°œ usernameë§ˆë‹¤)
    if username_count % random.randint(15, 25) == 0:
        break_time = random.randint(60, 720)  # 1-12ë¶„
        print(f"\nì¤‘ê°„ íœ´ì‹ ì‹œì‘ (ì´ {break_time//60}ë¶„ {break_time%60}ì´ˆ)...")
        show_countdown(break_time, "ì¤‘ê°„")

    # ëŒ€ê·œëª¨ íœ´ì‹ (80-100ê°œ usernameë§ˆë‹¤)
    if username_count % random.randint(80, 100) == 0:
        break_time = random.randint(1800, 7200)  # 30ë¶„-2ì‹œê°„
        hours = break_time // 3600
        minutes = (break_time % 3600) // 60
        print(f"\nëŒ€ê·œëª¨ íœ´ì‹ ì‹œì‘ (ì´ {hours}ì‹œê°„ {minutes}ë¶„)...")
        show_countdown(break_time, "ëŒ€ê·œëª¨")

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
def main():
    # Google Sheets API ì„¤ì •
    SPREADSHEET_ID = '1RdnS9IsC1TbTi356J5W-Pb66oaJ7xUhVZr-pTlJTwxQ'
    RANGE_NAME = 'A:A'  # Username í•„ë“œê°€ ìˆëŠ” ì—´ (Sheet ì´ë¦„ ì œê±°)

    # Google Sheets API ì¸ì¦ ë° ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„±
    creds = get_credentials()
    service = build('sheets', 'v4', credentials=creds)

    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    sheet = service.spreadsheets()
    result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()
    values = result.get('values', [])

    if not values:
        print('ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return

    # í—¤ë” ì œê±° (ì²« ë²ˆì§¸ í–‰ ê±´ë„ˆë›°ê¸°)
    usernames = [row[0] for row in values[1:] if row]  # ë¹ˆ í–‰ ì œì™¸

    # í¬ë¡¤ë§ ê¸°ê°„ ì…ë ¥ ë°›ê¸°
    while True:
        try:
            weeks = int(input("\ní¬ë¡¤ë§í•  ê¸°ê°„ì„ ì£¼ ë‹¨ìœ„ë¡œ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 9ì£¼(63ì¼) = 9): "))
            if weeks > 0:
                break
            print("1 ì´ìƒì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ë¡œê·¸ì¸ ì •ë³´ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)
    login_file_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "0_insta_login.txt")
    with open(login_file_path, 'r', encoding='utf-8') as f:
        profile_name = f.read().strip()

    # ì‚¬ìš©ì ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)
    user_data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "user_data", profile_name)

    try:
        # MongoDB ì—°ê²°
        collection_feed, collection_influencer = connect_mongodb()
        if collection_feed is None and collection_influencer is None:
            print("MongoDB ì—°ê²° ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return

        # ì´ë¯¸ ì²˜ë¦¬ëœ ê²Œì‹œë¬¼ URL ë¡œë“œ
        processed_posts = load_processed_posts(collection_feed)
        print("ì´ë¯¸ ì²˜ë¦¬ëœ ê²Œì‹œë¬¼ URL ë¡œë“œ ì™„ë£Œ")

        # ê° ì‚¬ìš©ìëª…ì— ëŒ€í•´ í¬ë¡¤ë§ ìˆ˜í–‰
        for username in usernames:
            try:
                # ì´ë¯¸ í¬ë¡¤ë§ëœ ê³„ì •ì¸ì§€ í™•ì¸
                already_crawled, crawl_date = check_already_crawled(service, SPREADSHEET_ID, username)
                if already_crawled:
                    print(f"\n{username} ê³„ì •ì€ ì´ë¯¸ {crawl_date}ì— í¬ë¡¤ë§ë˜ì—ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue

                # Chrome ì˜µì…˜ ì„¤ì •
                options = Options()
                options.add_argument("--start-maximized")
                options.add_experimental_option("detach", True)
                options.add_argument("disable-blink-features=AutomationControlled")
                options.add_experimental_option("excludeSwitches", ["enable-logging"])
                options.add_argument(f"user-data-dir={user_data_dir}")
                options.add_argument("--disable-application-cache")
                options.add_argument("--disable-cache")

                # ìºì‹œì™€ ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë¡œê·¸ì¸ ì •ë³´ ìœ ì§€)
                clear_chrome_data(user_data_dir)

                # ìƒˆë¡œìš´ Chrome ë“œë¼ì´ë²„ ì‹œì‘
                driver = webdriver.Chrome(options=options)

                print(f"\n{username} ê³„ì • í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                profile_url = f"https://www.instagram.com/{username}/"
                print(f"\ní”„ë¡œí•„ URL({profile_url})ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                driver.get(profile_url)
                
                # í”„ë¡œí•„ í˜ì´ì§€ì˜ ì£¼ìš” ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                try:
                    # í”„ë¡œí•„ ì´ë¯¸ì§€ë‚˜ ê²Œì‹œë¬¼ ê·¸ë¦¬ë“œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "div._aagv"))
                    )
                    print("í”„ë¡œí•„ í˜ì´ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    print(f"í”„ë¡œí•„ í˜ì´ì§€ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    raise

                # í¬ë¡¤ë§ ì‹¤í–‰ ë° ê²Œì‹œë¬¼ ìˆ˜ ë°›ê¸°
                post_count = crawl_instagram_posts(driver, username, weeks, collection_feed)
                
                # ë¦´ìŠ¤ ë¶„ì„ ìˆ˜í–‰
                print(f"\n{username} ê³„ì •ì˜ ë¦´ìŠ¤ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                reels_analyzer = ReelsAnalyzer(driver)  # ê¸°ì¡´ ë“œë¼ì´ë²„ ì¬ì‚¬ìš©
                reels_result = reels_analyzer.analyze_reels_views(f"https://www.instagram.com/{username}/")
                
                print(f"\n[ë¦´ìŠ¤ ë¶„ì„ ê²°ê³¼]")
                print(f"í‰ê·  ì¡°íšŒìˆ˜: {int(reels_result['average_views']):,}íšŒ")
                print(f"ì „ì²´ ë¦´ìŠ¤ ìˆ˜: {reels_result['total_reels']}ê°œ")
                print(f"ê³„ì‚° ë°©ì‹: {reels_result['calculation_method']}")
                
                # ë¦´ìŠ¤ ì¡°íšŒìˆ˜ ì—…ë°ì´íŠ¸
                update_reels_views(collection_influencer, username, reels_result['average_views'])
                
                # í¬ë¡¤ë§ ë‚ ì§œì™€ ê²Œì‹œë¬¼ ìˆ˜ ì—…ë°ì´íŠ¸
                update_crawl_date(service, SPREADSHEET_ID, username, post_count)
                
                # ë¸Œë¼ìš°ì € ì¢…ë£Œ
                print(f"\n{username} ê³„ì • í¬ë¡¤ë§ ì™„ë£Œ. ë¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                driver.quit()
                
                # ê³„ì • ê°„ í¬ë¡¤ë§ ë”œë ˆì´
                wait_time = random.uniform(10, 20)
                print(f"\në‹¤ìŒ ê³„ì •ìœ¼ë¡œ ì´ë™í•˜ê¸° ì „ {wait_time:.1f}ì´ˆ ëŒ€ê¸°...")
                time.sleep(wait_time)

            except Exception as e:
                error_message = f"{datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')} - {str(e)}"
                print(f"{username} ê³„ì • í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_message}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡
                update_crawl_date(service, SPREADSHEET_ID, username, 0, error_message)
                if 'driver' in locals():
                    driver.quit()
                continue

            # íœ´ì‹ ì‹œê°„ ê´€ë¦¬
            take_break(usernames.index(username) + 1)

    except Exception as e:
        print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    finally:
        print("\nëª¨ë“  ê³„ì •ì˜ í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        input("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”...")

if __name__ == "__main__":
    main()
